{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d7248-5f65-41f0-b730-c82e5e8cf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c27c4d-bb03-4b2c-b7ff-d6502fe15624",
   "metadata": {},
   "source": [
    "## Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109fc325-b3b0-48f7-a7df-5a929d279423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for NYC TLC Yellow Taxi trip data\n",
    "base_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{}-{}.parquet\"\n",
    "\n",
    "# Year and months to download (focusing on the first 3 months of the year)\n",
    "year = 2025\n",
    "months = [\"01\", \"02\", \"03\"]  # Jan, Feb, Mar\n",
    "\n",
    "# Folder structure\n",
    "folder_path = \"data\"\n",
    "os.makedirs(folder_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca360f-1007-4d95-8b84-b6503f2c5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)\n",
    "            print(f\"SUCCESS: Downloaded {save_path}\")\n",
    "        else:\n",
    "            print(f\"ERROR: Failed to download {url} (Status code: {response.status_code})\")\n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION: Error downloading {url} -> {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139842b4-ef5a-4e92-abfb-2f47919983fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a29e4-216f-4058-a3b2-365a3e2b7570",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2f733-8039-4535-98af-c29403081b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection details\n",
    "def get_postgres_connection():\n",
    "    return psycopg2.connect(\n",
    "        host = \"localhost\",\n",
    "        dbname = \"nyc_taxi\",\n",
    "        user = \"postgres\",\n",
    "        password = \"diana6508\",\n",
    "        port = 5432\n",
    "    )\n",
    "\n",
    "# Column ordering\n",
    "columns_order = [\n",
    "    \"VendorID\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"RatecodeID\",\n",
    "    \"store_and_fwd_flag\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"payment_type\",\n",
    "    \"fare_amount\",\n",
    "    \"extra\",\n",
    "    \"mta_tax\",\n",
    "    \"tip_amount\",\n",
    "    \"tolls_amount\",\n",
    "    \"improvement_surcharge\",\n",
    "    \"total_amount\",\n",
    "    \"congestion_surcharge\",\n",
    "    \"Airport_fee\",\n",
    "    \"cbd_congestion_fee\"]\n",
    "\n",
    "# Download + Load pipeline\n",
    "for month in months:\n",
    "    file_name = f\"yellow_tripdata_{year}-{month}.parquet\"\n",
    "    url = base_url.format(year, month)\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    download_file(url, save_path)\n",
    "\n",
    "    # read parquet\n",
    "    print(f\"Reading Parquet: {file_name}\")\n",
    "    df = pd.read_parquet(save_path)\n",
    "\n",
    "    # clean & reorder columns\n",
    "    print(\"Columns in Parquet:\", df.columns.tolist())\n",
    "\n",
    "    # Ensure optional columns exist; default to 0 if missing\n",
    "    optional_zero_cols = [\"airport_fee\", \"cbd_congestion_fee\"]\n",
    "    for col in optional_zero_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    required_cols = [\n",
    "        \"VendorID\",\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\",\n",
    "        \"passenger_count\",\n",
    "        \"trip_distance\",\n",
    "        \"RatecodeID\",\n",
    "        \"store_and_fwd_flag\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"payment_type\",\n",
    "        \"fare_amount\",\n",
    "        \"extra\",\n",
    "        \"mta_tax\",\n",
    "        \"tip_amount\",\n",
    "        \"tolls_amount\",\n",
    "        \"improvement_surcharge\",\n",
    "        \"total_amount\",\n",
    "        \"congestion_surcharge\",\n",
    "        \"airport_fee\",\n",
    "        \"cbd_congestion_fee\"\n",
    "    ]\n",
    "\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Required column {col} is missing from {file_name}\")\n",
    "\n",
    "    # Reorder columns to match the table load order exactly\n",
    "    df = df[required_cols]\n",
    "\n",
    "    # Cast integer-like columns so they don't look like 1.0 in CSV\n",
    "    int_cols = [\n",
    "        \"VendorID\",\n",
    "        \"passenger_count\",\n",
    "        \"RatecodeID\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"payment_type\"\n",
    "    ]\n",
    "    for col in int_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(\"Int64\")\n",
    "\n",
    "    # load into postgresql\n",
    "    print(f\"Loading into PostgreSQL: {file_name}\")\n",
    "\n",
    "    conn = get_postgres_connection()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Use raw schema by default\n",
    "    cur.execute(\"SET search_path TO raw, public;\")\n",
    "\n",
    "    # Write df to CSV buffer\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer, index=False, header=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Explicit COPY column list\n",
    "    copy_sql = \"\"\"\n",
    "        COPY yellow_taxi_trips_2025 (\n",
    "            VendorID,\n",
    "            tpep_pickup_datetime,\n",
    "            tpep_dropoff_datetime,\n",
    "            passenger_count,\n",
    "            trip_distance,\n",
    "            RatecodeID,\n",
    "            store_and_fwd_flag,\n",
    "            PULocationID,\n",
    "            DOLocationID,\n",
    "            payment_type,\n",
    "            fare_amount,\n",
    "            extra,\n",
    "            mta_tax,\n",
    "            tip_amount,\n",
    "            tolls_amount,\n",
    "            improvement_surcharge,\n",
    "            total_amount,\n",
    "            congestion_surcharge,\n",
    "            airport_fee,\n",
    "            cbd_congestion_fee\n",
    "        )\n",
    "        FROM STDIN WITH (FORMAT csv)\n",
    "    \"\"\"\n",
    "\n",
    "    cur.copy_expert(copy_sql, buffer)\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"SUCCESS: Loaded {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a86312-2053-45bb-93ab-d4f490edcab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (taxi_env)",
   "language": "python",
   "name": "taxi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
